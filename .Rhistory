fit_train=lm(cnt~.-instant-dteday-casual-registered-date-atemp,data=cd_train)
sort(vif(fit_train),decreasing = T)
fit_train=step(fit_train)
summary(fit_train)
formula(fit_train)
fit_train=lm(cnt ~ season + yr + holiday + weekday +
weathersit + temp + windspeed)
fit_train=lm(cnt ~ season + yr + holiday + weekday +
weathersit + temp + windspeed)
fit_train=lm(cnt~ season + yr + holiday + weekday +
weathersit + temp + windspeed)
fit_train=lm(cnt ~ season + yr + weekday + workingday + weathersit +
temp + hum + windspeed,data=cd_train)
#fit_train=lm(cnt~ season + yr + holiday + weekday +
#weathersit + temp + windspeed)
summary(fit_train)
fit_train=lm(cnt ~ season + yr + weekday  + weathersit +
temp + hum + windspeed,data=cd_train)
fit_train
#fit_train=lm(cnt~ season + yr + holiday + weekday +
#weathersit + temp + windspeed)
summary(fit_train)
fit_train=lm(cnt ~ season + yr + weekday  + weathersit +
temp  + windspeed,data=cd_train)
#fit_train=lm(cnt~ season + yr + holiday + weekday +
#weathersit + temp + windspeed)
summary(fit_train)
# lets check consistency of these variables on the validation data
fit_val=lm(cnt~. -instant-dteday-casual-registered-date,data=cd_val)
fit_val
vif(fit_val)
sort(vif(fit_train),decreasing = T)
sort(vif(fit_val),decreasing = T)
fit_val=lm(cnt~. -instant-dteday-casual-registered-date-atemp,data=cd_val)
sort(vif(fit_val),decreasing = T)
fit_val=step(fit_val)
summary(fit_val)
formula(fit_val)
fit_val=lm(cnt ~ season + yr + weekday + weathersit + temp + windspeed)
fit_val=lm(cnt~season + yr + weekday + weathersit + temp + windspeed)
fit_val=lm(cnt~season+yr+weekday+weathersit+temp+windspeed)
fit_val=lm(cnt~ season+yr+weekday+weathersit+temp+windspeed)
fit_val=lm(cnt~ season+yr+weekday+weathersit+temp+windspeed,data=cd_val)
fit_val
#fit_val=lm(cnt ~ season + yr + workingday + weathersit + temp + windspeed,data=cd_val)
summary(fit_val)
summary(fit_train)
fit_val=lm(cnt~ season+yr+weekday+weathersit+workingday+temp+windspeed,data=cd_val)
#fit_val=lm(cnt ~ season + yr + workingday + weathersit + temp + windspeed,data=cd_val)
summary(fit_val)
#fit_val=lm(cnt ~ season + yr + workingday + weathersit + temp + windspeed,data=cd_val)
summary(fit_val)
#fit_val=lm(cnt ~ season + yr + workingday + weathersit + temp + windspeed,data=cd_val)
summary(fit_val)
fit_val=lm(cnt~ season+yr+weekday+weathersit+temp+windspeed,data=cd_val)
#fit_val=lm(cnt ~ season + yr + workingday + weathersit + temp + windspeed,data=cd_val)
summary(fit_val)
fit_final=lm(cnt ~ season + yr + workingday + weathersit + temp + windspeed,data=cd_train)
summry(fit_final)
summary(fit_final)
summary(fit_final)
val.predict=predict(fit_final,cd_test)
val.predict
errors=cd_test$cnt-val.predic
errors=cd_test$cnt-val.predict
errors
rmse=errors**2 %>% mean() %>% sqrt()
rmse
fit.final=fit=lm(Interest.Rate ~ .-ID,
data=ld_train)
plot(cd_test$cnt,val.predict
plot(cd_test$cnt,val.predict)
plot(cd_test$cnt,val.predict)
plot(fit.final,1)
plot(fit_final,1)
plot(fit_final,2)
plot(fit_final,3)
plot(fit_final,4)
View(rg)
## ----
rg_train=read.csv("rg_train.csv",stringsAsFactors = FALSE)
rg_test=read.csv("rg_test.csv",stringsAsFactors = FALSE)
table(rg_train$Revenue.Grid)
library(dplyr)
glimpse(rg_train)
View(rg_train)
CreateDummies=function(data,var,freq_cutoff=0){
t=table(data[,var])
t=t[t>freq_cutoff]
t=sort(t)
categories=names(t)[-1]
for( cat in categories){
name=paste(var,cat,sep="_")
name=gsub(" ","",name)
name=gsub("-","_",name)
name=gsub("\\?","Q",name)
name=gsub("<","LT_",name)
name=gsub("\\+","",name)
name=gsub("\\/","_",name)
name=gsub(">","GT_",name)
name=gsub("=","EQ_",name)
name=gsub(",","",name)
data[,name]=as.numeric(data[,var]==cat)
}
data[,var]=NULL
return(data)
}
rg_test$Revenue.Grid=NA  ####Assigning the NA to dependent variable
rg_train$data='train'
rg_test$data='test'
rg=rbind(rg_train,rg_test)  ####combining test and train data
## ----
table(rg$children)
## ------------------------------------------------------------------------
rg = rg %>%
mutate(children=ifelse(children=="Zero",0,
substr(children,1,1)),
children=as.numeric(children))
View(rg)
lapply(dc,function(x) is.na(x))
sapply(dc,function(x) is.na(x))
dc = read_excel('default of credit card clients.xls',skip=1)
getwd()
library(readxl)
dc = read_excel('default of credit card clients.xls',skip=1)
View(dc)
glimpse(dc)
names(dc)[sapply(dc, function(x) is.character(x))]
sapply(dc,function(x) is.na(x))
sum(sapply(dc,function(x) is.na(x)))
set.seed(123)
s=sample(1:nrow(dc),0.8*nrow)
s=sample(1:nrow(dc),0.8*nrow(dc))
train_dc = dc[s,]
train_dc = dc[s,]
test_dc  = dc[-s,]
train_dc
test_dc
glimpse(train_dc)
glimpse(test_dc)
for_vif = lm(Y~.,data = train_dc)
for_vif = lm(dc$Y~.,data = train_dc)
dc$NEXT_PAY = dc$``default payment next month`
dc$NEXT_PAY = dc$default payment next month`
library(readxl)
dc = read_excel('default of credit card clients.xls',skip=1)
View(dc)
glimpse(dc)
getwd()
library(readxl)
dc = read_excel('default of credit card clients.xls',skip=1)
View(dc)
glimpse(dc)
library(readxl)
View(dc)
glimpse(dc)
library(dplyr)
glimpse(dc)
getwd()
library(readxl)
library(dplyr)
dc = read_excel('default of credit card clients.xls',skip=1)
View(dc)
rg_train=read.csv('rg_train.csv',stringsAsFactors = F)
rg_test=read.csv('rg_test.csv',stringsAsFactors = F)
rg_train=read.csv('rg_train.csv',stringsAsFactors = F)
rg_test=read.csv('rg_test.csv',stringsAsFactors = F)
rg_test$Revenue.Grid=NA
View(rg_train)
View(rg_test)
rg_train$data='train'
rg_test$data='test'
rg=rbind(rg_train,rg_test)
rg
View(rg)
rg = rg %>%
mutate(children=ifelse(children=="Zero",0,substr(children,1,1)),
children=as.numeric(children))
rg = rg %>%
mutate(children=ifelse(children=="Zero",0,substr(children,1,1)),
children=as.numeric(children))
View(rg)
rg = rg %>%
mutate(children=ifelse(children=="Zero",0,substr(children,1,1)),
children=as.numeric(children))
rg = rg %>%
mutate(children=ifelse(children=="Zero",0,substr(children,1,1)),
children=as.numeric(children))
rg = rg %>%
mutate(children=ifelse(children=="Zero",0,substr(children,1,1)),
children=as.numeric(children))
rg_train=read.csv('rg_train.csv',stringsAsFactors = F)
rg_test=read.csv('rg_test.csv',stringsAsFactors = F)
rg_test$Revenue.Grid=NA
View(rg_train)
View(rg_test)
rg_train$data='train'
rg_test$data='test'
rg=rbind(rg_train,rg_test)
rg = rg %>%
mutate(children=ifelse(children=="Zero",0,substr(children,1,1)),
children=as.numeric(children))
rg_train=read.csv('rg_train.csv',stringsAsFactors = F)
rg_test=read.csv('rg_test.csv',stringsAsFactors = F)
rg_test$Revenue.Grid=NA
View(rg_train)
View(rg_test)
rg=rbind(rg_train,rg_test)
rg = rg %>%
mutate(children=ifelse(children=="Zero",0,substr(children,1,1)),
children=as.numeric(children))
library(dplyr)
library(randomForest)
library(ggplot2)
library(tree)
library(cvTools)
rg = rg %>%
mutate(children=ifelse(children=="Zero",0,substr(children,1,1)),
children=as.numeric(children))
rg
View(rg)
rg=rg %>%
mutate(a1=as.numeric(substr(age_band,1,2)),
a2=as.numeric(substr(age_band,4,5)),
age=ifelse(substr(age_band,1,2)=="71",71,ifelse(age_band=="Unknown",NA,0.5*(a1+a2)))
) %>%
select(-a1,-a2,-age_band)
cat_cols=c("status","occupation","occupation_partner","home_status",
"family_income","self_employed",
"self_employed_partner","TVarea","gender","region")
for(cat in cat_cols){
rg=CreateDummies(rg,cat,50)
}
CreateDummies=function(data,var,freq_cutoff=0){
t=table(data[,var])
t=t[t>freq_cutoff]
t=sort(t)
categories=names(t)[-1]
for( cat in categories){
name=paste(var,cat,sep="_")
name=gsub(" ","",name)
name=gsub("-","_",name)
name=gsub("\\?","Q",name)
name=gsub("<","LT_",name)
name=gsub("\\+","",name)
name=gsub("\\/","_",name)
name=gsub(">","GT_",name)
name=gsub("=","EQ_",name)
name=gsub(",","",name)
data[,name]=as.numeric(data[,var]==cat)
}
data[,var]=NULL
return(data)
}
for(cat in cat_cols){
rg=CreateDummies(rg,cat,50)
}
rg=rg %>%
select(-post_code,-post_area)
rg$Revenue.Grid=as.numeric(rg$Revenue.Grid==1)
rg$Revenue.Grid
for(col in names(rg)){
if(sum(is.na(rg[,col]))>0 & !(col %in% c("data","Revenue.Grid"))){
rg[is.na(rg[,col]),col]=mean(rg[rg$data=='train',col],na.rm=T)
}
}
rg$Revenue.Grid=as.factor(rg$Revenue.Grid)
for(col in names(rg)){
if(sum(is.na(rg[,col]))>0 & !(col %in% c("data","Revenue.Grid"))){
rg[is.na(rg[,col]),col]=mean(rg[rg$data=='train',col],na.rm=T)
}
}
rg_train=rg %>% filter(data=='train') %>% select(-data)
rg_test=rg %>% filter(data=='test') %>% select (-data,-Revenue.Grid)
rg_train$data='train'
rg_test$data='test'
rg_train=read.csv('rg_train.csv',stringsAsFactors = F)
rg_test=read.csv('rg_test.csv',stringsAsFactors = F)
rg_test$Revenue.Grid=NA
View(rg_train)
View(rg_test)
rg_train$data='train'
rg_test$data='test'
rg=rbind(rg_train,rg_test)
rg = rg %>%
mutate(children=ifelse(children=="Zero",0,substr(children,1,1)),
children=as.numeric(children))
View(rg)
rg=rg %>%
mutate(a1=as.numeric(substr(age_band,1,2)),
a2=as.numeric(substr(age_band,4,5)),
age=ifelse(substr(age_band,1,2)=="71",71,ifelse(age_band=="Unknown",NA,0.5*(a1+a2)))
) %>%
select(-a1,-a2,-age_band)
cat_cols=c("status","occupation","occupation_partner","home_status",
"family_income","self_employed",
"self_employed_partner","TVarea","gender","region")
for(cat in cat_cols){
rg=CreateDummies(rg,cat,50)
}
rg=rg %>%
select(-post_code,-post_area)
rg$Revenue.Grid=as.numeric(rg$Revenue.Grid==1)
for(col in names(rg)){
if(sum(is.na(rg[,col]))>0 & !(col %in% c("data","Revenue.Grid"))){
rg[is.na(rg[,col]),col]=mean(rg[rg$data=='train',col],na.rm=T)
}
}
## For classification tree we'll need to convert response to factor type
rg$Revenue.Grid=as.factor(rg$Revenue.Grid)
for(col in names(rg)){
if(sum(is.na(rg[,col]))>0 & !(col %in% c("data","Revenue.Grid"))){
rg[is.na(rg[,col]),col]=mean(rg[rg$data=='train',col],na.rm=T)
}
}
rg_train=rg %>% filter(data=='train') %>% select(-data)
rg_test=rg %>% filter(data=='test') %>% select (-data,-Revenue.Grid)
set.seed(2)
s=sample(1:nrow(rg_train),0.8*nrow(rg_train))
rg_train1=rg_train[s,]
rg_train2=rg_train[-s,]
rg.tree=tree(Revenue.Grid~.-REF_NO,data=rg_train1)
val.score=predict(rg.tree,newdata = rg_train2,type='vector')[,2]
pROC::roc(rg_train2$Revenue.Grid,val.score)$auc #checking AUC
test.score=predict(rg.tree.final,newdata=rg_test,type='vector')[,2]
rg.tree.final=tree(Revenue.Grid~.-REF_NO,
data=rg_train)
test.score=predict(rg.tree.final,newdata=rg_test,type='vector')[,2]
rg.tree.final
pROC::roc(rg_train2$Revenue.Grid,val.score)$auc #checking AUC
rg.tree.final=tree(Revenue.Grid~.-REF_NO,
data=rg_train)
rg.tree.final
test.score=predict(rg.tree.final,newdata=rg_test,type='vector')[,2]
write.csv(test.score,"mysubmission_1.csv",row.names = F)
train.score=predict(rg.tree.final,newdata=rg_train,type='vector')[,2]
real=rg_train$Revenue.Grid
real
cutoffs=seq(0.001,0.999,0.001)
cutoffs
cutoff_data=data.frame(cutoff=99,Sn=99,Sp=99,KS=99,F5=99,F.1=99,M=99)
for(cutoff in cutoffs){
predicted=as.numeric(train.score>cutoff)
TP=sum(real==1 & predicted==1)
TN=sum(real==0 & predicted==0)
FP=sum(real==0 & predicted==1)
FN=sum(real==1 & predicted==0)
P=TP+FN
N=TN+FP
Sn=TP/P
Sp=TN/N
precision=TP/(TP+FP)
recall=Sn
KS=(TP/P)-(FP/N)
F5=(26*precision*recall)/((25*precision)+recall)
F.1=(1.01*precision*recall)/((.01*precision)+recall)
M=(4*FP+FN)/(5*(P+N))
cutoff_data=rbind(cutoff_data,c(cutoff,Sn,Sp,KS,F5,F.1,M))
}
cutoff_data=data.frame(cutoff=99,Sn=99,Sp=99,KS=99,F5=99,F.1=99,M=99)
cutoff_data=data.frame(cutoff=99,Sn=99,Sp=99,KS=99,F5=99,F.1=99,M=99)
cutoff_data
for(cutoff in cutoffs){
predicted=as.numeric(train.score>cutoff)
TP=sum(real==1 & predicted==1)
TN=sum(real==0 & predicted==0)
FP=sum(real==0 & predicted==1)
FN=sum(real==1 & predicted==0)
P=TP+FN
N=TN+FP
Sn=TP/P
Sp=TN/N
precision=TP/(TP+FP)
recall=Sn
KS=(TP/P)-(FP/N)
F5=(26*precision*recall)/((25*precision)+recall)
F.1=(1.01*precision*recall)/((.01*precision)+recall)
M=(4*FP+FN)/(5*(P+N))
cutoff_data=rbind(cutoff_data,c(cutoff,Sn,Sp,KS,F5,F.1,M))
}
cutoff_data
cutoff_data=cutoff_data[-1,]
cutoff_data
my_cutoff=cutoff_data$cutoff[which.max(cutoff_data$KS)]
my_cutoff
test.predicted=as.numeric(test.score>my_cutoff)
test.predicted
write.csv(test.predicted,"proper_submission_file_name.csv",row.names = F)
print('Hello')
212467/359000
getwd()
setwd("D:/DS_and_AI/Module_Predictive_Analytics_in_R/Project/Real_Estate")
getwd()
library(dplyr)
library(randomForest)
library(ggplot2)
library(dplyr)
library(tree)
library(cvTools)
housing_train = read.csv('housing_train.csv',stringsAsFactors = F)
housing_test = read.csv('housing_test.csv',stringsAsFactors = F)
#creating data variable for test and train data
housing_test$data = 'test'
housing_train$data = 'train'
#creating Price column for test data
housing_test$Price = NA
#combining the test and train data
housing_all = rbind(housing_train,housing_test)
summary(housing_all$Price)
summary(housing_train$Price)
glimpse(housing_all)
#######################
for(col in names(housing_all)){
##replacing the NA with mean
if(sum(is.na(housing_all[,col]))>0 & (col %in% c("Landsize","BuildingArea","YearBuilt","Bedroom2","Car","Bathroom"))){
housing_all[is.na(housing_all[,col]),col]=round(mean(housing_all[,col],na.rm=T))
}
}
glimpse(housing_all)
############################
glimpse(housing_all)
#housing_all$Method = NULL
housing_all$Postcode = NULL
housing_all$Address = NULL
housing_all$CouncilArea = NULL
#checking for NA
apply(housing_all, 2, function(x) any(is.na(x)))
#Crearing Dummies
CreateDummies=function(data,var,freq_cutoff=0){
t=table(data[,var])
t=t[t>freq_cutoff]
t=sort(t)
categories=names(t)[-1]
for( cat in categories){
name=paste(var,cat,sep="_")
name=gsub(" ","",name)
name=gsub("-","_",name)
name=gsub("\\?","Q",name)
name=gsub("<","LT_",name)
name=gsub("\\+","",name)
data[,name]=as.numeric(data[,var]==cat)
}
data[,var]=NULL
return(data)
}
#housing_all = CreateDummies(housing_all,"Car",200) #NA are there
housing_all = CreateDummies(housing_all,'Suburb',100)
housing_all = CreateDummies(housing_all,"SellerG",50)
#housing_all = CreateDummies(housing_all,"CouncilArea",100)
housing_all = CreateDummies(housing_all,"Method",100)
housing_all = CreateDummies(housing_all,"Type",100)
summary(housing_all$Distance)
summary(housing_all$YearBuilt)
housing_all$Distance = 15 - housing_all$Distance
glimpse(housing_all)
lapply(housing_all,function(x) sum(is.na(x)))
for(col in names(housing_all)){
##replacing the NA with mean
if(sum(is.na(housing_all[,col]))>0 & !(col %in% c("data","Price"))){
housing_all[is.na(housing_all[,col]),col]=round(mean(housing_all[,col],na.rm=T))
}
}
#Splitting the data
housing_train=housing_all %>% filter(data=='train') %>% select(-data)
housing_test=housing_all %>% filter(data=='test') %>% select(-data,-Price)
names(housing_train)
names(housing_test)
set.seed(1)
s=sample(1:nrow(housing_train),0.80*nrow(housing_train))
housing_train1=housing_train[s,]
housing_train2=housing_train[-s,]
param=list(mtry=c(5,10,15,20,25,30,35,40,45,50,55,60,65,70),
ntree=c(50,100,200,500,600,650,700,800,900,1000,1200,1400,1500,1700,2000,2100,2200),
maxnodes=c(5,10,15,20,30,50,70,90,120,150,170,180,190,200,210,220,230,240,250,
260,270,280,290,300,320,350),
nodesize=c(1,2,5,10,13,15,20,25,30,35,40,45,50))
param
subset_paras=function(full_list_para,n=10){
all_comb=expand.grid(full_list_para)
s=sample(1:nrow(all_comb),n)
subset_para=all_comb[s,]
return(subset_para)
}
num_trials=50
my_params=subset_paras(param,num_trials)
my_params
## cvtuning for regression
## this code might take too long to run
## no need to execute completely in class
myerror=9999999
for(i in 1:num_trials){
print(paste0('starting iteration:',i))
# uncomment the line above to keep track of progress
params=my_params[i,]
k=cvTuning(randomForest,Price~.,
data =housing_train,
tuning =params,
folds = cvFolds(nrow(housing_train), K=10, type = "random"),
seed =2
)
score.this=k$cv[,2]
if(score.this<myerror){
print(params)
# uncomment the line above to keep track of progress
myerror=score.this
print(myerror)
# uncomment the line above to keep track of progress
best_params=params
}
print('DONE')
# uncomment the line above to keep track of progress
}
